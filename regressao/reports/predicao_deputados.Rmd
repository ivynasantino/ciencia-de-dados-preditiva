---
title: "Predição de deputados eleitos"
author: "Ivyna Santino"
output:
  html_document:
    df_print: paged
    toc: yes
    toc_float: yes
  html_notebook:
    toc: yes
    toc_float: yes
---

Para esse checkpoint iremos utilizar conhecimentos sobre classificação para prever quais candidatos à Câmara de Deputados serão eleitos nas eleições de 2014. 

```{r setup, warning=FALSE, message=FALSE, include=FALSE}
library(tidyverse)
library(here)
library(caret)
library(mlbench)

theme_set(theme_minimal())
```


```{r, message=FALSE, warning=FALSE}
train <- read.csv(here("data/situacao/train.csv"))
```

```{r, message=FALSE, warning=FALSE}
test = importa_eleicao("data/situacao/test.csv")
```

Tratando os dados:

```{r, warning=FALSE, message=FALSE}
train <- train %>% 
  select(-cargo,
         -sequencial_candidato,
         -nome,
         -uf,
         -estado_civil,
         -grau,
         -ano,
         -sexo,
         -partido)
```

Seria bom tratar os dados numéricos com mediana, média...

```{r, warning=FALSE, message=FALSE}

```


```{r, warning=FALSE, message=FALSE}
train$ocupacao <- as.factor(train$ocupacao)
```

Perguntas:

1.Há desbalanceamento das classes (isto é, uma classe tem muito mais instâncias que outra)? 
  Em que proporção? 
  Quais efeitos colaterais o desbalanceamento de classes pode causar no classificador? 
  Como você poderia tratar isso?


```{r, warning=FALSE, message=FALSE}
quantidade_situacao <- table(train$situacao)
```


2.Treine: um modelo de regressão logística, uma árvore de decisão e um modelo de adaboost. 
  Tune esses modelos usando validação cruzada e controle overfitting se necessário, considerando as particularidades de cada modelo.  


```{r, warning=FALSE, message=FALSE}
# VC <- trainControl(method = "repeatedcv",
#                    number = 5,
#                    repeats = 5,
#                    sampling = "smote",
#                    verboseIter = TRUE)
# 
# modelo <- train(situacao ~ .,
#                 data = train,
#                 method = "regLogistic",
#                 trControl = VC)
```

```{r, warning=FALSE, message=FALSE}
#saveRDS(modelo, file="modelo.rds")
modelo <- readRDS(file="modelo.rds")
```

```{r, warning=FALSE, message=FALSE}
modelo
```


```{r, warning=FALSE, message=FALSE}
# modelo.knn <- train(situacao ~ .,
#                 data = train,
#                 method = "knn",
#                 trControl = VC)
```

```{r, warning=FALSE, message=FALSE}
modelo.knn
```


```{r, warning=FALSE, message=FALSE}
#saveRDS(modelo.knn, file="modelo_knn.rds")
modelo.knn <- readRDS(file="modelo_knn.rds")
```


```{r, warning=FALSE, message=FALSE}
# modelo.dt <- train(situacao ~ .,
#                 data = train,
#                 method = "rpart",
#                 trControl = VC)
```

```{r, warning=FALSE, message=FALSE}
#saveRDS(modelo.dt, file="modelo_dt.rds")
modelo_dt <- readRDS(file="modelo_dt.rds")
```

```{r, warning=FALSE, message=FALSE}
modelo.dt
```



```{r, warning=FALSE, message=FALSE}
modelo.ada <- train(situacao ~ .,
                data = train,
                method = "adaboost",
                trControl = VC)
```

```{r, warning=FALSE, message=FALSE}
#saveRDS(modelo.ada, file="modelo_ada.rds")
modelo.ada <- readRDS(file="modelo_ada.rds")
```


```{r, warning=FALSE, message=FALSE}
modelo.ada
```

3.Reporte acurácia, precision, recall e f-measure no treino e validação. 
  Há uma grande diferença de desempenho no treino/validação? 
  Como você avalia os resultados? Justifique sua resposta.


```{r, warning=FALSE, message=FALSE}

```

4.Interprete as saídas dos modelos. 
  Quais atributos parecem ser mais importantes de acordo com cada modelo? 
  Crie pelo menos um novo atributo que não está nos dados originais e estude o impacto desse atributo

```{r, message=FALSE, warning=FALSE}
train <- read.csv(here("data/situacao/train.csv"))
```

```{r, warning=FALSE, message=FALSE}
train$homem <- ifelse(train$sexo == "HOMEM", TRUE, FALSE)

train$homem <- as.factor(train$homem)
```

```{r, warning=FALSE, message=FALSE}
train$deputado <- ifelse(train$ocupacao == "DEPUTADO", TRUE, FALSE)

train$deputado <- as.factor(train$deputado)
```


```{r, warning=FALSE, message=FALSE}
train$ens_superior <- ifelse(train$grau == "SUPERIOR COMPLETO", TRUE, FALSE)

train$ens_superior <- as.factor(train$ens_superior)
```

```{r, warning=FALSE, message=FALSE}
train <- train %>% 
  select(-cargo,
         -sequencial_candidato,
         -nome,
         -uf,
         -estado_civil,
         -grau,
         -ano,
         -sexo,
         -partido)
```

```{r, warning=FALSE, message=FALSE}
modelo.ada.novo <- train(situacao ~ .,
                data = train,
                method = "adaboost",
                trControl = VC)
```

```{r, warning=FALSE, message=FALSE}
#saveRDS(modelo.ada.novo, file="modelo_ada_novo.rds")
modelo.ada.novo <- readRDS(file="modelo_ada_novo.rds")
```

```{r, warning=FALSE, message=FALSE}
modelo.ada.novo
```


5.Envie seus melhores modelos à competição do Kaggle. 
  Faça pelo menos uma submissão. 
  Sugestões para melhorar o modelo: 
    Experimente outros modelos (e.g. SVM, RandomForests e GradientBoosting).
    Experimente balancear as classes,  caso estejam desbalanceadas.
    Crie pelo menos um novo atributo.

```{r, warning=FALSE, message=FALSE}

```









