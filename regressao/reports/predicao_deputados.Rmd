---
title: "Predição de deputados eleitos"
author: "Ivyna Santino"
output:
  html_document:
    df_print: paged
    toc: yes
    toc_float: yes
  html_notebook:
    toc: yes
    toc_float: yes
---

Para esse checkpoint iremos utilizar conhecimentos sobre classificação para prever quais candidatos à Câmara de Deputados serão eleitos nas eleições de 2014. 

```{r setup, warning=FALSE, message=FALSE, include=FALSE}
library(tidyverse)
library(here)
library(caret)
library(rpart)

theme_set(theme_minimal())
```


```{r, message=FALSE, warning=FALSE}
train <- read.csv(here("data/situacao/train.csv"))
```

```{r, message=FALSE, warning=FALSE}
test = read.csv(here("data/situacao/test.csv"))
```

Tratando os dados:

```{r, warning=FALSE, message=FALSE}
train <- train %>% 
  select(-cargo,
         -sequencial_candidato,
         -nome,
         -uf,
         -estado_civil,
         -grau,
         -ano,
         -sexo,
         -partido)
```


```{r, warning=FALSE, message=FALSE}
train$ocupacao <- as.factor(train$ocupacao)
```

Perguntas:

###1.Há desbalanceamento das classes (isto é, uma classe tem muito mais instâncias que outra)? Em que proporção? Quais efeitos colaterais o desbalanceamento de classes pode causar no classificador? Como você poderia tratar isso?


```{r, warning=FALSE, message=FALSE}
quantidade_situacao <- table(train$situacao)
quantidade_situacao
```
[RESPOSTAS]

### 2.Treine: um modelo de regressão logística, uma árvore de decisão e um modelo de adaboost. Tune esses modelos usando validação cruzada e controle overfitting se necessário, considerando as particularidades de cada modelo.  


```{r, warning=FALSE, message=FALSE}
# VC <- trainControl(method = "repeatedcv",
#                    number = 5,
#                    repeats = 5,
#                    sampling = "smote",
#                    verboseIter = TRUE)
# 
# modelo <- train(situacao ~ .,
#                 data = train,
#                 method = "regLogistic",
#                 trControl = VC)
```

```{r, warning=FALSE, message=FALSE}
#saveRDS(modelo, file="modelo.rds")
modelo <- readRDS(file="modelo.rds")
```

```{r, warning=FALSE, message=FALSE}
modelo
```
```{r, warning=FALSE, message=FALSE}
confusion.rl <- confusionMatrix(modelo)
confusion.rl
```


```{r, warning=FALSE, message=FALSE}
# modelo.knn <- train(situacao ~ .,
#                 data = train,
#                 method = "knn",
#                 trControl = VC)
```

```{r, warning=FALSE, message=FALSE}
modelo.knn
```


```{r, warning=FALSE, message=FALSE}
#saveRDS(modelo.knn, file="modelo_knn.rds")
modelo.knn <- readRDS(file="modelo_knn.rds")
```

```{r, warning=FALSE, message=FALSE}
confusion.knn <- confusionMatrix(modelo.knn)
confusion.knn
```


```{r, warning=FALSE, message=FALSE}
# modelo.dt <- train(situacao ~ .,
#                 data = train,
#                 method = "rpart",
#                 trControl = VC)
```

```{r, warning=FALSE, message=FALSE}
#saveRDS(modelo.dt, file="modelo_dt.rds")
modelo.dt <- readRDS(file="modelo_dt.rds")
```

```{r, warning=FALSE, message=FALSE}
modelo.dt
```
```{r}
confusion.dt <- confusionMatrix(modelo.dt)
confusion.dt
```


```{r, warning=FALSE, message=FALSE}
# modelo.ada <- train(situacao ~ .,
#                 data = train,
#                 method = "adaboost",
#                 trControl = VC)
```

```{r, warning=FALSE, message=FALSE}
#saveRDS(modelo.ada, file="modelo_ada.rds")
modelo.ada <- readRDS(file="modelo_ada.rds")
```


```{r, warning=FALSE, message=FALSE}
modelo.ada
```


```{r}
confusion.ada <- confusionMatrix(modelo.ada)
confusion.ada
```


### 3.Reporte acurácia, precision, recall e f-measure no treino e validação. Há uma grande diferença de desempenho no treino/validação? Como você avalia os resultados? Justifique sua resposta.

vp: verdadeiros positivos table1
fp: falsos positivos table3
vn: verdadeiros negativos table2
fn: falsos negativos table4

```{r, warning=FALSE, message=FALSE}
precision <- function(vp, fp) {
  resultado = vp/(vp + fp)
  return(resultado)
}

recall <- function(vp, fn) {
  resultado = vp/(vp + fn)
  return(resultado)
}

f_measure <- function(p, r) {
  resultado = 2*((p * r)/(p + r))
  return(resultado)
}

acuracia <- function(vp, fp, vn, fn) {
  resultado = (vp + fn)/(vp + fp + vn + fn)
  return(resultado)
}
```


#### Regressão logística

```{r, warning=FALSE, message=FALSE}
precision.rl <- precision(confusion.rl$table[1], confusion.rl$table[3])
recall.rl <- recall(confusion.rl$table[1], confusion.rl$table[2])
f_measure.rl <- f_measure(precision.rl, recall.rl)
acuracia.rl <- acuracia(confusion.rl$table[1], 
                        confusion.rl$table[3], 
                        confusion.rl$table[2], 
                        confusion.rl$table[4])
```

```{r, warning=FALSE, message=FALSE}
precision.rl
recall.rl
f_measure.rl
acuracia.rl
```

#### Knn

```{r, warning=FALSE, message=FALSE}
precision.knn <- precision(confusion.knn$table[1], confusion.knn$table[3])
recall.knn <- recall(confusion.knn$table[1], confusion.knn$table[2])
f_measure.knn <- f_measure(precision.knn, recall.knn)
acuracia.knn <- acuracia(confusion.knn$table[1], 
                        confusion.knn$table[3], 
                        confusion.knn$table[2], 
                        confusion.knn$table[4])
```

```{r, warning=FALSE, message=FALSE}
precision.knn
recall.knn
f_measure.knn
acuracia.knn
```

#### Árvore de decisão

```{r, warning=FALSE, message=FALSE}
precision.dt <- precision(confusion.dt$table[1], confusion.dt$table[3])
recall.dt <- recall(confusion.dt$table[1], confusion.dt$table[2])
f_measure.dt <- f_measure(precision.dt, recall.dt)
acuracia.dt <- acuracia(confusion.dt$table[1], 
                        confusion.dt$table[3], 
                        confusion.dt$table[2], 
                        confusion.dt$table[4])
```

```{r, warning=FALSE, message=FALSE}
precision.dt
recall.dt
f_measure.dt
acuracia.dt
```

#### Adaboost

```{r, warning=FALSE, message=FALSE}
precision.ada <- precision(confusion.ada$table[1], confusion.ada$table[3])
recall.ada <- recall(confusion.ada$table[1], confusion.ada$table[2])
f_measure.ada <- f_measure(precision.ada, recall.ada)
acuracia.ada <- acuracia(confusion.ada$table[1], 
                        confusion.ada$table[3], 
                        confusion.ada$table[2], 
                        confusion.ada$table[4])
```

```{r, warning=FALSE, message=FALSE}
precision.ada
recall.ada
f_measure.ada
acuracia.ada
```

[RESPOSTA]


4.Interprete as saídas dos modelos. 
  Quais atributos parecem ser mais importantes de acordo com cada modelo? 
  Crie pelo menos um novo atributo que não está nos dados originais e estude o impacto desse atributo

```{r, message=FALSE, warning=FALSE}
train <- read.csv(here("data/situacao/train.csv"))
```

```{r, warning=FALSE, message=FALSE}
train$homem <- ifelse(train$sexo == "HOMEM", TRUE, FALSE)

train$homem <- as.factor(train$homem)
```

```{r, warning=FALSE, message=FALSE}
train$deputado <- ifelse(train$ocupacao == "DEPUTADO", TRUE, FALSE)

train$deputado <- as.factor(train$deputado)
```


```{r, warning=FALSE, message=FALSE}
train$ens_superior <- ifelse(train$grau == "SUPERIOR COMPLETO", TRUE, FALSE)

train$ens_superior <- as.factor(train$ens_superior)
```

```{r, warning=FALSE, message=FALSE}
train <- train %>% 
  select(-cargo,
         -sequencial_candidato,
         -nome,
         -uf,
         -estado_civil,
         -grau,
         -ano,
         -sexo,
         -partido)
```

```{r, warning=FALSE, message=FALSE}
modelo.ada.novo <- train(situacao ~ .,
                data = train,
                method = "adaboost",
                trControl = VC)
```

```{r, warning=FALSE, message=FALSE}
#saveRDS(modelo.ada.novo, file="modelo_ada_novo.rds")
modelo.ada.novo <- readRDS(file="modelo_ada_novo.rds")
```

```{r, warning=FALSE, message=FALSE}
modelo.ada.novo
```


5.Envie seus melhores modelos à competição do Kaggle. 
  Faça pelo menos uma submissão. 
  Sugestões para melhorar o modelo: 
    Experimente outros modelos (e.g. SVM, RandomForests e GradientBoosting).
    Experimente balancear as classes,  caso estejam desbalanceadas.
    Crie pelo menos um novo atributo.

```{r, warning=FALSE, message=FALSE}

```









