---
title: "Predição de votação de candidatos à Câmara Federal de Deputados"
author: "Ivyna Santino"
date: "4 de novembro de 2018"
output:
  html_document:
    df_print: paged
    toc: yes
    toc_float: yes
  html_notebook:
    toc: yes
    toc_float: yes
---

```{r setup, warning=FALSE, message=FALSE, include=FALSE}
library(tidyverse)
library(here)
library(caret)

theme_set(theme_minimal())
```

### Descrição do problema:
O objetivo desse checkpoint é construir modelos preditivos de regressão para a predição de votação de candidatos à Câmara Federal de Deputados.

### Iniciando
#### Importando dados
Antes de tudo, iremos importar os dados de treino e teste:

```{r, warning=FALSE, message=FALSE, include=FALSE}
importa_eleicao <- function(dataset_path) {
  read = read.csv(here(paste("data/all", dataset_path, sep = "/")))
  return(read)
}

```

```{r, warning=FALSE, message=FALSE}
train = importa_eleicao("train.csv")
test = importa_eleicao("test.csv")
```

#### Preparando dataframe:

Nessa parte inicial, optei por retirar algumas variáveis contidas na base de dados afim de faciltar a criação dos modelos posteriormente.
```{r, warning=FALSE, message=FALSE}
train <- train %>% 
  select(-cargo,
         -sequencial_candidato,
         -ocupacao,
         -uf,
         -nome)
```

### Criação dos modelos

- Modelo de regressão Ridge
- Modelo de regressão Lasso
- Modelo KNN

```{r, warning=FALSE, message=FALSE}

modelo_ridge <- train(votos ~ .,
                     data = train,
                     method = "ridge")


modelo_lasso <- train(votos ~ .,
                     data = train,
                     method = "lasso")


modelo_knn <- train(votos ~ .,
                     data = train,
                     method = "knn")

```



```{r, warning=FALSE, message=FALSE}
modelo_ridge
```


```{r, warning=FALSE, message=FALSE}
modelo_lasso
```

```{r, warning=FALSE, message=FALSE}
modelo_knn
```

### Comparação dos modelos em termos do erro RMSE

Para ficar mais fácil a observação dos valores mínimos, é mais intuitivo observar da seguinte forma:

```{r, warning=FALSE, message=FALSE}
min(modelo_ridge$results$RMSE)
```

```{r, warning=FALSE, message=FALSE}
min(modelo_lasso$results$RMSE)
```

```{r, warning=FALSE, message=FALSE}
min(modelo_knn$results$RMSE)
```

Dessa forma, podemos observar o modelo feito com o knn teve o menor resultado para o RMSE e o mais alto foi o método feito pelo lasso.


### Importância das variáveis em modelos de regressão Ridge e Lasso

```{r, warning=FALSE, message=FALSE}
ggplot(varImp(modelo_ridge)) +
geom_col(fill = "#F08080") +
labs(title = "Importância das variáveis do modelo Ridge",
     y = "Importância",
     x = "Variável(is)")
```

```{r, warning=FALSE, message=FALSE}
ggplot(varImp(modelo_lasso)) +
geom_col(fill = "#FFA07A") +
labs(title = "Importância das variáveis do modelo Lasso",
     y = "Importância",
     x = "Variável(is)")
```


```{r, warning=FALSE, message=FALSE}
ggplot(varImp(modelo_knn)) +
geom_col(fill = "#F4A460") +
labs(title = "Importância das variáveis do modelo Knn",
     y = "Importância",
     x = "Variável(is)")
  
```

A partir das visualizações acima, podemos observar que as seguintes variáveis tem um maior nível de importância para o modelo:

- total_receita
- total_despesa
- recursos_de_pessoas_juridicas

Obs.: o critério de seleção das variáveis mais importantes se deu pelo nível de importância acima de 50.

Dessa forma, podemos descartar recursos_de_pessoas_fisicas, quantidade_fornecedores, quantidade_despesas, media_receita, recursos_de_partido_politico, quantidade_doadores, quantidade_doacoes, grau, estado_civil, partido, sexo, ano, recursos_proprios, media_despesa e recursos_de_outros_candidatos.comites, deixando o modelo mais enxuto e possibilitando a construção de um novo modelo com menos variáveis e mais representativo.


### Formando novo modelo

Para formar um novo modelo, selecionei as variáveis com maior nível de importância de acordo com os resultados vistos acima e criei um novo dataframe.

```{r, warning=FALSE, message=FALSE}
modelo_select <- train %>% 
  select(total_receita,
         total_despesa,
         recursos_de_pessoas_juridicas,
         votos)
```

### Retreinando o melhor modelo

```{r, warning=FALSE, message=FALSE}
modelo_select_knn <- train(votos ~ .,
                     data = modelo_select,
                     method = "knn")

```


```{r, warning=FALSE, message=FALSE}
modelo_select_knn
```

Da mesma forma do modelo anterior, é mais intuitivo observar o valor mínimo do RMSE abaixo:

```{r, warning=FALSE, message=FALSE}
min(modelo_select_knn$results$RMSE)
```

Podemos observar dessa vez que o valor do RMSE aumentou em comparação ao modelo com todas as variáveis.

### Use esse último modelo treinado para prever os dados de teste disponíveis no challenge que criamos na plataforma Kaggle

```{r, warning=FALSE, message=FALSE}
submissao <- test %>% 
  select(sequencial_candidato)

test <- test %>% 
  select(-cargo,
         -sequencial_candidato,
         -ocupacao,
         -uf,
         -nome)
```


```{r, warning=FALSE, message=FALSE}
predicao <- predict(modelo_select_knn, test)
submissao$votos <- predicao

submissao <- submissao %>% 
  select(ID = sequencial_candidato,
         votos = votos)
```

```{r, warning=FALSE, message=FALSE}
write.csv(x = submissao,
          file = "../data/sample_submission.csv",
          row.names = FALSE)


```




