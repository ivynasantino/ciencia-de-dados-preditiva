---
title: "Predição de votação de candidatos à Câmara Federal de Deputados"
author: "Ivyna Santino"
date: "4 de novembro de 2018"
output:
  html_document:
    df_print: paged
    toc: yes
    toc_float: yes
  html_notebook:
    toc: yes
    toc_float: yes
---

```{r setup, warning=FALSE, message=FALSE}
library(tidyverse)
library(here)
library(caret)

theme_set(theme_minimal())
```

### Descrição do problema:
O objetivo desse checkpoint é construir modelos preditivos de regressão para a predição de votação de candidatos à Câmara Federal de Deputados.

### Iniciando
#### Importando dados
Antes de tudo, iremos importar os dados de treino e teste:

```{r, warning=FALSE, message=FALSE, include=FALSE}
importa_eleicao <- function(dataset_path) {
  read = read.csv(here(paste("data/all", dataset_path, sep = "/")))
  return(read)
}

```

```{r, warning=FALSE, message=FALSE}
train = importa_eleicao("train.csv")
test = importa_eleicao("test.csv")
```

#### Preparando dataframe:

Nessa parte inicial, optei por retirar algumas variáveis contidas na base de dados afim de faciltar a criação dos modelos posteriormente.
```{r, warning=FALSE, message=FALSE}
train <- train %>% 
  select(-cargo,
         -sequencial_candidato,
         -ocupacao,
         -uf,
         -nome)
```

### Criação dos modelos

- Modelo de regressão Ridge
- Modelo de regressão Lasso
- Modelo KNN

```{r, warning=FALSE, message=FALSE}

modelo_ridge <- train(votos ~ .,
                     data = train,
                     method = "ridge")


modelo_lasso <- train(votos ~ .,
                     data = train,
                     
                     method = "lasso")


modelo_knn <- train(votos ~ .,
                     data = train,
                     method = "knn")

```



```{r, warning=FALSE, message=FALSE}
modelo_ridge
# Ridge Regression 
# 
# 7476 samples
#   18 predictors
# 
# No pre-processing
# Resampling: Bootstrapped (25 reps) 
# Summary of sample sizes: 7476, 7476, 7476, 7476, 7476, 7476, ... 
# Resampling results across tuning parameters:
# 
#   lambda  RMSE      Rsquared   MAE     
#   0e+00   56515.38  0.3442496  16932.85
#   1e-04   37477.05  0.3962081  16466.81
#   1e-01   38050.98  0.3902056  16440.98
# 
# RMSE was used to select the optimal model using the smallest value.
# The final value used for the model was lambda = 1e-04.
```


```{r, warning=FALSE, message=FALSE}
modelo_lasso

# The lasso 
# 
# 7476 samples
#   18 predictors
# 
# No pre-processing
# Resampling: Bootstrapped (25 reps) 
# Summary of sample sizes: 7476, 7476, 7476, 7476, 7476, 7476, ... 
# Resampling results across tuning parameters:
# 
#   fraction  RMSE      Rsquared   MAE     
#   0.1       41296.23  0.3360462  17264.30
#   0.5       58228.20  0.2717016  16931.75
#   0.9       78294.50  0.2600462  17345.89
# 
# RMSE was used to select the optimal model using the smallest value.
# The final value used for the model was fraction = 0.1.

```

```{r, warning=FALSE, message=FALSE}
modelo_knn

# k-Nearest Neighbors 
# 
# 7476 samples
#   18 predictors
# 
# No pre-processing
# Resampling: Bootstrapped (25 reps) 
# Summary of sample sizes: 7476, 7476, 7476, 7476, 7476, 7476, ... 
# Resampling results across tuning parameters:
# 
#   k  RMSE      Rsquared   MAE     
#   5  37343.24  0.4268117  13959.22
#   7  35736.20  0.4583032  13460.61
#   9  34970.26  0.4753359  13182.20
# 
# RMSE was used to select the optimal model using the smallest value.
# The final value used for the model was k = 9.

```

### Comparação dos modelos em termos do erro RMSE

Resposta

### Importância das variáveis em modelos de regressão Ridge e Lasso

```{r, warning=FALSE, message=FALSE}
ggplot(varImp(modelo_ridge)) +
geom_col(fill = "#F08080") +
labs(title = "Importância das variáveis do modelo Ridge",
     y = "Importância",
     x = "Variável(is)")
```

```{r, warning=FALSE, message=FALSE}
ggplot(varImp(modelo_lasso)) +
geom_col(fill = "#FFA07A") +
labs(title = "Importância das variáveis do modelo Lasso",
     y = "Importância",
     x = "Variável(is)")
```


```{r, warning=FALSE, message=FALSE}
ggplot(varImp(modelo_knn)) +
geom_col(fill = "#F4A460") +
labs(title = "Importância das variáveis do modelo Knn",
     y = "Importância",
     x = "Variável(is)")
  
```

A partir das visualizações acima, podemos observar que as seguintes variáveis tem um maior nível de importância para o modelo:

- total_receita
- total_despesa
- recursos_de_pessoas_juridicas

Obs.: o critério de seleção das variáveis mais importantes se deu pelo nível de importância acima de 50.

Dessa forma, podemos descartar recursos_de_pessoas_fisicas, quantidade_fornecedores, quantidade_despesas, media_receita, recursos_de_partido_politico, quantidade_doadores, quantidade_doacoes, grau, estado_civil, partido, sexo, ano, recursos_proprios, media_despesa e recursos_de_outros_candidatos.comites, deixando o modelo mais enxuto e possibilitando a construção de um novo modelo com menos variáveis e mais representativo.


### Formando novo modelo

Para formar um novo modelo, selecionei as variáveis com maior nível de importância de acordo com os resultados vistos acima e criei um novo dataframe.

```{r, warning=FALSE, message=FALSE}
modelo_select <- train %>% 
  select(total_receita,
         total_despesa,
         recursos_de_pessoas_juridicas,
         votos)
```

### Retreinando o melhor modelo

```{r, warning=FALSE, message=FALSE}
modelo_select_ridge <- train(votos ~ .,
                     data = modelo_select,
                     method = "ridge")

modelo_select_lasso <- train(votos ~ .,
                     data = modelo_select,
                     method = "lasso")

modelo_select_knn <- train(votos ~ .,
                     data = modelo_select,
                     method = "knn")

```


```{r, warning=FALSE, message=FALSE}
modelo_select_ridge
# 
# Ridge Regression 
# 
# 7476 samples
#    3 predictors
# 
# No pre-processing
# Resampling: Bootstrapped (25 reps) 
# Summary of sample sizes: 7476, 7476, 7476, 7476, 7476, 7476, ... 
# Resampling results across tuning parameters:
# 
#   lambda  RMSE      Rsquared   MAE     
#   0e+00   36295.67  0.3992942  17539.31
#   1e-04   36295.39  0.3993021  17540.27
#   1e-01   36538.17  0.3939808  17424.94
# 
# RMSE was used to select the optimal model using the smallest value.
# The final value used for the model was lambda = 1e-04.

```


```{r, warning=FALSE, message=FALSE}
modelo_select_lasso
# 
# The lasso 
# 
# 7476 samples
#    3 predictors
# 
# No pre-processing
# Resampling: Bootstrapped (25 reps) 
# Summary of sample sizes: 7476, 7476, 7476, 7476, 7476, 7476, ... 
# Resampling results across tuning parameters:
# 
#   fraction  RMSE     Rsquared   MAE     
#   0.1       43632.6  0.3755933  24930.51
#   0.5       37904.7  0.3789884  17850.19
#   0.9       37816.1  0.3815954  17628.47
# 
# RMSE was used to select the optimal model using the smallest value.
# The final value used for the model was fraction = 0.9.

```


```{r, warning=FALSE, message=FALSE}
modelo_select_knn
# 
# k-Nearest Neighbors 
# 
# 7476 samples
#    3 predictors
# 
# No pre-processing
# Resampling: Bootstrapped (25 reps) 
# Summary of sample sizes: 7476, 7476, 7476, 7476, 7476, 7476, ... 
# Resampling results across tuning parameters:
# 
#   k  RMSE      Rsquared   MAE     
#   5  37975.11  0.4046912  14366.88
#   7  36573.01  0.4329369  13947.41
#   9  35643.31  0.4509839  13642.85
# 
# RMSE was used to select the optimal model using the smallest value.
# The final value used for the model was k = 9.

```

Resposta: comparação com o modelo anterior e dos novos RMSE.


### Use esse último modelo treinado para prever os dados de teste disponíveis no challenge que criamos na plataforma Kaggle (Links para um site externo)

Dúvida
