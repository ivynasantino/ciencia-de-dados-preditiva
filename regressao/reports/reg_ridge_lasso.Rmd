---
title: "R Notebook"
output: html_notebook
---

```{r setup, warning=FALSE, message=FALSE}
library(tidyverse)
library(here)
library(caret)

theme_set(theme_minimal())
```

Descrição do problema:

- Usando todas as variáveis disponíveis, tune (usando validação cruzada): 
  (i) um modelo de regressão Ridge ok
  (ii) um modelo de regressão Lasso ok
  (iii) um modelo KNN. Para os modelos de regressão linear, o parâmetro a ser tunado é o lambda (penalização dos coeficientes) e o KNN o número de vizinhos. (9 pts.)

- Compare os três modelos em termos do erro RMSE de validação cruzada. (9 pts.)
- Quais as variáveis mais importantes segundo o modelo de regressão Ridge e Lasso?  Variáveis foram descartadas pelo Lasso? Quais? (9 pts.)
- Re-treine o melhor modelo (usando os melhores valores de parâmetros encontrados em todos os dados, sem usar validação cruzada). (9 pts.)
- Use esse último modelo treinado para prever os dados de teste disponíveis no challenge que criamos na plataforma Kaggle (Links para um site externo)
Links para um site externo (9 pts.)

```{r, warning=FALSE, message=FALSE}
importa_eleicao <- function(dataset_path) {
  read = read_csv(here(paste("data/all", dataset_path, sep = "/")))
  return(read)
}

train = importa_eleicao("train.csv")
test = importa_eleicao("test.csv")
```


```{r, warning=FALSE, message=FALSE}
train <- train %>% 
  select(-cargo,
         -sequencial_candidato,
         -ocupacao,
         -uf,
         -nome)
```


```{r, warning=FALSE, message=FALSE}

modelo_lm <- train(votos ~ .,
                     data = train,
                     method = "lm")


modelo_ridge <- train(votos ~ .,
                     data = train,
                     method = "ridge")


modelo_lasso <- train(votos ~ .,
                     data = train,
                     method = "lasso")


modelo_knn <- train(votos ~ .,
                     data = train,
                     method = "knn")

```


```{r, warning=FALSE, message=FALSE}
modelo_lm

# 
# Linear Regression 
# 
# 7476 samples
#   18 predictor
# 
# No pre-processing
# Resampling: Bootstrapped (25 reps) 
# Summary of sample sizes: 7476, 7476, 7476, 7476, 7476, 7476, ... 
# Resampling results:
# 
#   RMSE      Rsquared   MAE     
#   95680.41  0.3233439  17523.38
# 
# Tuning parameter 'intercept' was held constant at a value of TRUE


```


```{r, warning=FALSE, message=FALSE}
modelo_ridge
# 
# Ridge Regression 
# 
# 7476 samples
#   18 predictor
# 
# No pre-processing
# Resampling: Bootstrapped (25 reps) 
# Summary of sample sizes: 7476, 7476, 7476, 7476, 7476, 7476, ... 
# Resampling results across tuning parameters:
# 
#   lambda  RMSE          Rsquared   MAE         
#   0e+00   1.813757e+12  0.3355068  3.528742e+10
#   1e-04   3.937651e+04  0.3651657  1.644839e+04
#   1e-01   4.014603e+04  0.3592090  1.643595e+04
# 
# RMSE was used to select the optimal model using the smallest value.
# The final value used for the model was lambda = 1e-04.

```


```{r, warning=FALSE, message=FALSE}
modelo_lasso
# 
# The lasso 
# 
# 7476 samples
#   18 predictor
# 
# No pre-processing
# Resampling: Bootstrapped (25 reps) 
# Summary of sample sizes: 7476, 7476, 7476, 7476, 7476, 7476, ... 
# Resampling results across tuning parameters:
# 
#   fraction  RMSE      Rsquared   MAE     
#   0.1       42667.20  0.3486232  17703.69
#   0.5       65992.53  0.3013075  17097.56
#   0.9       91408.60  0.2962026  17648.44
# 
# RMSE was used to select the optimal model using the smallest value.
# The final value used for the model was fraction = 0.1.

```

```{r, warning=FALSE, message=FALSE}
modelo_knn
# 
# k-Nearest Neighbors 
# 
# 7476 samples
#   18 predictor
# 
# No pre-processing
# Resampling: Bootstrapped (25 reps) 
# Summary of sample sizes: 7476, 7476, 7476, 7476, 7476, 7476, ... 
# Resampling results across tuning parameters:
# 
#   k  RMSE      Rsquared   MAE     
#   5  36436.60  0.4381170  13778.84
#   7  35221.21  0.4650971  13295.98
#   9  34604.39  0.4788859  13016.16
# 
# RMSE was used to select the optimal model using the smallest value.
# The final value used for the model was k = 9.

```


Fazendo modelos com as variáveis escolhidas no checkpoint anterior:

cola:

qnt_fornec - qtd_desp = 0.99
qnt_desp - tot_receita = 0.76
pes_jur - tot-receita = 0.85
pes_jur - tot_desp = 0.84
tot_receita - tot_desp = 0.99
qtd_doacoes - qtd_doadores = 1

com votos
tot_desp = 0.61
tot_receita = 0.6
pes_juridica = 0.55

escolha para modelo: 


```{r, warning=FALSE, include=FALSE}

```

